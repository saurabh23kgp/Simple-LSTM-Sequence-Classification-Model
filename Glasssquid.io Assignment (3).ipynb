{"cells":[{"metadata":{},"cell_type":"markdown","source":"Possible improvements to my work:-\n\n1)Use Transfer Learning :-Create languege model first via transfer learning (using weights of Wikitext 103) and them fine tune this model with the Text of both Train and Validation sets. After that, use this Languege model to classify the text.\n\n2) Proper hyperparameter tuning, which include adding more dense layers and changing the batchsize, changing the lenght of the dictionary and maxlength allowed for each text"},{"metadata":{},"cell_type":"markdown","source":"**CODE STARTS FROM HERE**"},{"metadata":{},"cell_type":"markdown","source":"Import the standard Keras library"},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys, os, re, csv, codecs, numpy as np, pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\nfrom keras.layers import Bidirectional, GlobalMaxPool1D\nfrom keras.models import Model\nfrom keras import initializers, regularizers, constraints, optimizers, layers\nfrom sklearn.preprocessing import LabelBinarizer, LabelEncoder\nfrom sklearn.metrics import confusion_matrix\n\nfrom tensorflow import keras\nlayers = keras.layers\nmodels = keras.models","execution_count":117,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/trainin/train.csv\")\ntest = pd.read_csv('../input/validation/valid.csv')","execution_count":118,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking for any null values in the train dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().any(),test.isnull().any()\n","execution_count":119,"outputs":[{"output_type":"execute_result","execution_count":119,"data":{"text/plain":"(Section    False\n Label      False\n dtype: bool, Section    False\n Label      False\n dtype: bool)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":120,"outputs":[{"output_type":"execute_result","execution_count":120,"data":{"text/plain":"                                             Section  Label\n0  Description ÛÏJacobs National Security Soluti...      3\n1  Duties will include Applying complex analysis ...      5\n2  Job Qualifications Active Top Secret security ...      6\n3                               Essential Functions       5\n4  Other Essential Functions Must be able to comm...      5","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Section</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>Description ÛÏJacobs National Security Soluti...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>Duties will include Applying complex analysis ...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>Job Qualifications Active Top Secret security ...</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>Essential Functions</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>Other Essential Functions Must be able to comm...</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_sentences_train=train[\"Section\"]\nlist_sentences_test=test['Section']\ny=train['Label']","execution_count":121,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use sklearn utility to convert label strings to numbered index\nencoder = LabelEncoder()\nencoder.fit(y)\ny= encoder.transform(y)","execution_count":122,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = np.max(y) + 1\ny = keras.utils.to_categorical(y, num_classes)","execution_count":123,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below we tokenize the words in the sentences with a maximum length of 20000 of the dictionary "},{"metadata":{"trusted":true},"cell_type":"code","source":"max_features = 20000\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(list_sentences_train))\nlist_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\nlist_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)","execution_count":124,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"totalNumWords = [len(one_comment) for one_comment in list_tokenized_train]","execution_count":125,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting the distribution of the number of words in sentences."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(totalNumWords,bins = np.arange(0,410,10))\nplt.show()","execution_count":126,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"As we can see, most of the sentence length is about 150+."},{"metadata":{"trusted":true},"cell_type":"code","source":"maxlen = 200\nX_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\nX_te = pad_sequences(list_tokenized_test, maxlen=maxlen)","execution_count":134,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Making Functions for recall, precision and F1 score as these are not available as metrics in Keras Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\n\ndef recall_m(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + K.epsilon())\n        return recall\n\ndef precision_m(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","execution_count":135,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defining the model architecture of the model which includes the embedding layer in the beginning followed by the LSTM unit followed by few dense units along with the dropouts"},{"metadata":{"trusted":true},"cell_type":"code","source":"inp = Input(shape=(maxlen, )) #maxlen=150 as defined earlier\nembed_size = 128\nx = Embedding(max_features, embed_size)(inp)\nx = LSTM(60, return_sequences=True,name='lstm_layer')(x)\nx = GlobalMaxPool1D()(x)\nx = Dropout(0.1)(x)\nx = Dense(50, activation=\"relu\")(x)\nx = Dropout(0.1)(x)\nx = Dense(9, activation=\"sigmoid\")(x)\nmodel = Model(inputs=inp, outputs=x)\nmodel.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['acc',f1_m,precision_m, recall_m])","execution_count":136,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We feed the output into a Sigmoid layer. The reason why sigmoid is used is because we are trying to achieve a binary classification(1,0) for each of the 9 labels, and the sigmoid function will squash the output between the bounds of 0 and 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\nepochs = 20\nmodel.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)","execution_count":137,"outputs":[{"output_type":"stream","text":"Train on 2812 samples, validate on 313 samples\nEpoch 1/20\n2812/2812 [==============================] - 10s 3ms/step - loss: 0.5137 - acc: 0.7882 - f1_m: 0.0716 - precision_m: 0.1162 - recall_m: 0.1058 - val_loss: 0.3103 - val_acc: 0.8889 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\nEpoch 2/20\n2812/2812 [==============================] - 9s 3ms/step - loss: 0.3112 - acc: 0.8849 - f1_m: 0.0661 - precision_m: 0.3493 - recall_m: 0.0377 - val_loss: 0.2965 - val_acc: 0.8889 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\nEpoch 3/20\n2812/2812 [==============================] - 9s 3ms/step - loss: 0.3053 - acc: 0.8871 - f1_m: 0.0528 - precision_m: 0.3680 - recall_m: 0.0288 - val_loss: 0.2899 - val_acc: 0.8889 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\nEpoch 4/20\n2812/2812 [==============================] - 9s 3ms/step - loss: 0.2963 - acc: 0.8857 - f1_m: 0.0590 - precision_m: 0.3362 - recall_m: 0.0327 - val_loss: 0.2834 - val_acc: 0.8889 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\nEpoch 5/20\n2812/2812 [==============================] - 9s 3ms/step - loss: 0.2824 - acc: 0.8898 - f1_m: 0.1203 - precision_m: 0.4921 - recall_m: 0.0707 - val_loss: 0.2516 - val_acc: 0.8967 - val_f1_m: 0.1615 - val_precision_m: 0.8250 - val_recall_m: 0.0898\nEpoch 6/20\n2812/2812 [==============================] - 9s 3ms/step - loss: 0.2463 - acc: 0.9034 - f1_m: 0.3295 - precision_m: 0.7035 - recall_m: 0.2236 - val_loss: 0.2003 - val_acc: 0.9244 - val_f1_m: 0.5707 - val_precision_m: 0.7660 - val_recall_m: 0.4557\nEpoch 7/20\n2812/2812 [==============================] - 9s 3ms/step - loss: 0.1995 - acc: 0.9234 - f1_m: 0.5805 - precision_m: 0.7399 - recall_m: 0.4816 - val_loss: 0.1759 - val_acc: 0.9336 - val_f1_m: 0.6517 - val_precision_m: 0.7740 - val_recall_m: 0.5639\nEpoch 8/20\n2812/2812 [==============================] - 9s 3ms/step - loss: 0.1724 - acc: 0.9350 - f1_m: 0.6653 - precision_m: 0.7786 - recall_m: 0.5826 - val_loss: 0.1505 - val_acc: 0.9411 - val_f1_m: 0.7048 - val_precision_m: 0.7786 - val_recall_m: 0.6459\nEpoch 9/20\n2812/2812 [==============================] - 9s 3ms/step - loss: 0.1543 - acc: 0.9425 - f1_m: 0.7115 - precision_m: 0.8047 - recall_m: 0.6388 - val_loss: 0.1381 - val_acc: 0.9499 - val_f1_m: 0.7523 - val_precision_m: 0.8184 - val_recall_m: 0.6967\nEpoch 10/20\n2812/2812 [==============================] - 9s 3ms/step - loss: 0.1395 - acc: 0.9482 - f1_m: 0.7404 - precision_m: 0.8344 - recall_m: 0.6672 - val_loss: 0.1269 - val_acc: 0.9528 - val_f1_m: 0.7655 - val_precision_m: 0.8306 - val_recall_m: 0.7119\nEpoch 11/20\n2812/2812 [==============================] - 9s 3ms/step - loss: 0.1171 - acc: 0.9566 - f1_m: 0.7847 - precision_m: 0.8736 - recall_m: 0.7138 - val_loss: 0.1154 - val_acc: 0.9549 - val_f1_m: 0.7777 - val_precision_m: 0.8332 - val_recall_m: 0.7306\nEpoch 12/20\n2812/2812 [==============================] - 9s 3ms/step - loss: 0.0978 - acc: 0.9627 - f1_m: 0.8163 - precision_m: 0.8990 - recall_m: 0.7486 - val_loss: 0.1002 - val_acc: 0.9602 - val_f1_m: 0.8061 - val_precision_m: 0.8656 - val_recall_m: 0.7548\nEpoch 13/20\n2812/2812 [==============================] - 9s 3ms/step - loss: 0.0805 - acc: 0.9725 - f1_m: 0.8670 - precision_m: 0.9321 - recall_m: 0.8119 - val_loss: 0.0816 - val_acc: 0.9670 - val_f1_m: 0.8422 - val_precision_m: 0.8856 - val_recall_m: 0.8032\nEpoch 14/20\n2812/2812 [==============================] - 9s 3ms/step - loss: 0.0612 - acc: 0.9802 - f1_m: 0.9062 - precision_m: 0.9535 - recall_m: 0.8638 - val_loss: 0.0764 - val_acc: 0.9688 - val_f1_m: 0.8509 - val_precision_m: 0.8864 - val_recall_m: 0.8185\nEpoch 15/20\n2812/2812 [==============================] - 9s 3ms/step - loss: 0.0479 - acc: 0.9846 - f1_m: 0.9279 - precision_m: 0.9644 - recall_m: 0.8947 - val_loss: 0.0774 - val_acc: 0.9741 - val_f1_m: 0.8760 - val_precision_m: 0.9146 - val_recall_m: 0.8411\nEpoch 16/20\n2812/2812 [==============================] - 9s 3ms/step - loss: 0.0396 - acc: 0.9876 - f1_m: 0.9426 - precision_m: 0.9697 - recall_m: 0.9175 - val_loss: 0.0620 - val_acc: 0.9819 - val_f1_m: 0.9152 - val_precision_m: 0.9386 - val_recall_m: 0.8930\nEpoch 17/20\n2812/2812 [==============================] - 9s 3ms/step - loss: 0.0330 - acc: 0.9909 - f1_m: 0.9585 - precision_m: 0.9720 - recall_m: 0.9456 - val_loss: 0.0594 - val_acc: 0.9812 - val_f1_m: 0.9109 - val_precision_m: 0.9404 - val_recall_m: 0.8833\nEpoch 18/20\n2812/2812 [==============================] - 9s 3ms/step - loss: 0.0262 - acc: 0.9929 - f1_m: 0.9678 - precision_m: 0.9787 - recall_m: 0.9573 - val_loss: 0.0591 - val_acc: 0.9812 - val_f1_m: 0.9114 - val_precision_m: 0.9347 - val_recall_m: 0.8895\nEpoch 19/20\n2812/2812 [==============================] - 9s 3ms/step - loss: 0.0241 - acc: 0.9934 - f1_m: 0.9697 - precision_m: 0.9780 - recall_m: 0.9619 - val_loss: 0.0611 - val_acc: 0.9826 - val_f1_m: 0.9177 - val_precision_m: 0.9351 - val_recall_m: 0.9016\nEpoch 20/20\n2812/2812 [==============================] - 9s 3ms/step - loss: 0.0201 - acc: 0.9947 - f1_m: 0.9760 - precision_m: 0.9800 - recall_m: 0.9723 - val_loss: 0.0573 - val_acc: 0.9837 - val_f1_m: 0.9242 - val_precision_m: 0.9395 - val_recall_m: 0.9094\n","name":"stdout"},{"output_type":"execute_result","execution_count":137,"data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7ef8d4561ef0>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Converting the labels in Validation dataset (named here as 'test')"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test=test['Label']\nencoder = LabelEncoder()\nencoder.fit(y_test)\ny_test= encoder.transform(y_test)\nnum_classes = np.max(y_test) + 1\ny_test = keras.utils.to_categorical(y_test, num_classes)","execution_count":138,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predicting for validation dataset (named as Test Dataset)"},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate(X_te, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\nprint('Test F1:', score[2])\nprint('Test Precision:', score[3])\nprint('Test Recall:', score[4])","execution_count":139,"outputs":[{"output_type":"stream","text":"Test loss: 0.05675649005071739\nTest accuracy: 0.9843704700469971\nTest F1: 0.9293485879898071\nTest Precision: 0.9435844421386719\nTest Recall: 0.9162499904632568\n","name":"stdout"}]}],"metadata":{"colab":{"name":"Published BBC text BOW","version":"0.3.2","views":{},"default_view":{},"provenance":[{"file_id":"1IlP-4XDM1_5NRdR5g_6DbIT-YvdwKGvn","timestamp":1528444855450}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}